{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from sklearn import base\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = pd.read_csv('data/conflict.csv')\n",
    "pred = pd.read_csv('data/pak_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['event_date'] =  pd.to_datetime(conflict['event_date'], format='%d %B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['Battles'] = conflict['event_type'] == 'Battles'\n",
    "conflict['Explosions'] = conflict['event_type'] == 'Explosions/Remote violence'\n",
    "conflict['Protests'] = conflict['event_type'] == 'Protests'\n",
    "conflict['Riots'] = conflict['event_type'] == 'Riots'\n",
    "conflict['Strategic developments'] = conflict['event_type'] == 'Strategic developments'\n",
    "conflict['Violence against civilians'] = conflict['event_type'] == 'Violence against civilians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['month_year'] = conflict.event_date.values.astype('datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict  = conflict[['month_year','latitude','longitude','Battles','Explosions','Protests','Riots',\n",
    "                      'Strategic developments','Violence against civilians','fatalities','admin1','admin2','admin3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['fatalities_battles'] = conflict['fatalities'] * conflict['Battles']\n",
    "conflict['fatalities_explosions'] = conflict['fatalities'] * conflict['Explosions']\n",
    "conflict['fatalities_protests'] = conflict['fatalities'] * conflict['Protests']\n",
    "conflict['fatalities_riots'] = conflict['fatalities'] * conflict['Riots']\n",
    "conflict['fatalities_strategic'] = conflict['fatalities'] * conflict['Strategic developments']\n",
    "conflict['fatalities_civilian'] = conflict['fatalities'] * conflict['Violence against civilians']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = conflict.groupby(['month_year','latitude','longitude']).agg({'Battles':'sum',\n",
    "                                                             'Explosions':'sum',\n",
    "                                                             'Protests':'sum',\n",
    "                                                             'Riots':'sum',\n",
    "                                                             'Strategic developments':'sum',\n",
    "                                                             'Violence against civilians':'sum',\n",
    "                                                             'fatalities_battles':'sum',\n",
    "                                                             'fatalities_explosions':'sum',\n",
    "                                                             'fatalities_protests':'sum',\n",
    "                                                             'fatalities_riots':'sum',\n",
    "                                                             'fatalities_strategic':'sum',\n",
    "                                                             'fatalities_civilian':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.loc[:, ~pred.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.rename(columns={\"x\": \"longitude\", \"y\": \"latitude\", \"pak_ppp_2015\": \"pop\", \"pak07povmpi\": \"pov\", \n",
    "                     \"F182013.v4c_web.stable_lights.avg_vis\": \"nl\", \"index_1\": \"temp\", \"layer\": \"elev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.dropna(subset=['pop', 'pov','nl','temp','elev']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(pred[['longitude','latitude']],conflict, on = ['longitude','latitude'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X.month_year.isnull(),['month_year']] = pd.to_datetime('2010-01-01')\n",
    "X = X[X['month_year'] != pd.to_datetime('2019-10-01')]\n",
    "X['month_year'] = X['month_year'].dt.strftime('%Y-%m')\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2010-01-01','2019-09-01', \n",
    "              freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "coor = pred[['longitude','latitude']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [coor,dates]\n",
    "data = list(itertools.product(*a))\n",
    "df = pd.DataFrame(data, columns=['coor','month_year'])\n",
    "df[['longitude','latitude']] = pd.DataFrame(df.coor.values.tolist(), index= df.index)\n",
    "df = df[['longitude','latitude','month_year']].sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(df,X, on = ['longitude','latitude','month_year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(pred,X, on = ['longitude','latitude'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = X.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                  + row['Violence against civilians']) != 0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['month'] = X.apply(lambda row: int(row['month_year'].split('-')[1]), axis=1)\n",
    "X['year'] = X.apply(lambda row: int(row['month_year'].split('-')[0]), axis=1)\n",
    "X['year'] = X['year'] - 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y_next'] = X.shift(-1).y\n",
    "X.loc[X.index.to_series().groupby([X['longitude'],X['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "y = X['y_next'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = X[self.col_names].values\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_transformer = ColumnTransformer([(\"onehot\", OneHotEncoder(categories='auto', sparse=False),slice(19,20))], \n",
    "                                        remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ColumnTransformer([(\"standard\", StandardScaler(),slice(12,19))], \n",
    "                                        remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    beta = 1.1\n",
    "\n",
    "    f1 = (1 + (beta**2))*p*r / ((beta**2) * p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnEstimator(base.BaseEstimator, base.ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, past, loss, metrics, opt, epochs):\n",
    "        self.past = past\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.opt = opt\n",
    "        self.model = Sequential()\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_list = X.tolist()\n",
    "        y_list = y.tolist()\n",
    "        n = len(X_list)\n",
    "        y_list = [y_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        X_list = [X_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        \n",
    "        to_remove = [i for i in range(len(y_list)) if True in [math.isnan(item) for item in y_list[i]]]\n",
    "\n",
    "        for index in sorted(to_remove, reverse=True):\n",
    "            del y_list[index]\n",
    "            del X_list[index]\n",
    "        y_list = [int(item[-1]) for item in y_list]\n",
    "        \n",
    "        y = np.array(y_list)\n",
    "        X = np.array(X_list)\n",
    "        \n",
    "        n_steps = X.shape[1]\n",
    "        n_features = X.shape[2]\n",
    "        \n",
    "        self.model.add(LSTM(10, input_shape=(n_steps, n_features)))\n",
    "        self.model.add(Dense(5, activation='tanh'))\n",
    "        self.model.add(Dense(10, activation='tanh'))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        self.model.compile(optimizer=self.opt, loss=self.loss, metrics=self.metrics)\n",
    "        \n",
    "        self.model.fit(X, y, epochs=self.epochs)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        X_list = X.tolist()\n",
    "        y_list = y.tolist()\n",
    "        n = len(X_list)\n",
    "        y_list = [y_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        X_list = [X_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        \n",
    "        to_remove = [i for i in range(len(y_list)) if True in [math.isnan(item) for item in y_list[i]]]\n",
    "\n",
    "        for index in sorted(to_remove, reverse=True):\n",
    "            del y_list[index]\n",
    "            del X_list[index]\n",
    "        y_list = [int(item[-1]) for item in y_list]\n",
    "        \n",
    "        y = np.array(y_list)\n",
    "        X = np.array(X_list)\n",
    "        \n",
    "        return self.model.evaluate(X, y, batch_size = X.shape[0])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_list = X.tolist()\n",
    "        n = len(X_list)\n",
    "        X_list = [X_list[i:i+self.past] for i in range(0, n - self.past +1, self.past)]\n",
    "        X = np.array(X_list)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['month_year'] < '2017-07'].copy()\n",
    "X_test = X[X['month_year'] >= '2017-07'].copy()\n",
    "\n",
    "X_train['y_next'] = X_train.shift(-1).y\n",
    "X_train.loc[X_train.index.to_series().groupby([X_train['longitude'], \n",
    "                                               X_train['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "X_test['y_next'] = X_test.shift(-1).y\n",
    "X_test.loc[X_test.index.to_series().groupby([X_test['longitude'], \n",
    "                                             X_test['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "y_train = X_train['y_next'].values\n",
    "\n",
    "y_test = X_test['y_next'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "pipe = Pipeline([\n",
    "        (\"columns\", ColumnSelectTransformer(['longitude','latitude','pop','pov','nl','temp','elev','Battles','Explosions',\n",
    "             'Protests','Riots','Strategic developments','Violence against civilians',\n",
    "             'fatalities_battles','fatalities_explosions','fatalities_protests','fatalities_riots',\n",
    "             'fatalities_strategic','fatalities_civilian','month','year','y'])),\n",
    "        (\"one_hot\", one_hot_transformer),\n",
    "        (\"scale\",scaler),\n",
    "        (\"rnn\", RnnEstimator(past, f_loss, [precision, recall, 'accuracy'], opt, 20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8658/8658 [==============================] - 4s 468us/sample - loss: 0.3584 - precision: 0.5742 - recall: 0.7862 - acc: 0.7976\n",
      "Epoch 2/20\n",
      "8658/8658 [==============================] - 3s 355us/sample - loss: 0.3121 - precision: 0.6219 - recall: 0.7871 - acc: 0.8266\n",
      "Epoch 3/20\n",
      "8658/8658 [==============================] - 3s 332us/sample - loss: 0.3074 - precision: 0.6194 - recall: 0.8064 - acc: 0.8283\n",
      "Epoch 4/20\n",
      "8658/8658 [==============================] - 3s 364us/sample - loss: 0.3100 - precision: 0.6141 - recall: 0.8093 - acc: 0.8254\n",
      "Epoch 5/20\n",
      "8658/8658 [==============================] - 3s 353us/sample - loss: 0.2978 - precision: 0.6222 - recall: 0.8201 - acc: 0.8309\n",
      "Epoch 6/20\n",
      "8658/8658 [==============================] - 3s 374us/sample - loss: 0.2985 - precision: 0.6206 - recall: 0.8200 - acc: 0.8292\n",
      "Epoch 7/20\n",
      "8658/8658 [==============================] - 3s 389us/sample - loss: 0.2972 - precision: 0.6209 - recall: 0.8215 - acc: 0.8314\n",
      "Epoch 8/20\n",
      "8658/8658 [==============================] - 3s 349us/sample - loss: 0.2976 - precision: 0.6289 - recall: 0.8096 - acc: 0.8341\n",
      "Epoch 9/20\n",
      "8658/8658 [==============================] - 4s 420us/sample - loss: 0.2918 - precision: 0.6310 - recall: 0.8172 - acc: 0.8336\n",
      "Epoch 10/20\n",
      "8658/8658 [==============================] - 3s 349us/sample - loss: 0.2914 - precision: 0.6295 - recall: 0.8213 - acc: 0.8348\n",
      "Epoch 11/20\n",
      "8658/8658 [==============================] - 3s 316us/sample - loss: 0.2955 - precision: 0.6292 - recall: 0.8194 - acc: 0.8360\n",
      "Epoch 12/20\n",
      "8658/8658 [==============================] - 3s 325us/sample - loss: 0.2916 - precision: 0.6315 - recall: 0.8205 - acc: 0.8361\n",
      "Epoch 13/20\n",
      "8658/8658 [==============================] - 3s 353us/sample - loss: 0.2938 - precision: 0.6294 - recall: 0.8219 - acc: 0.8350\n",
      "Epoch 14/20\n",
      "8658/8658 [==============================] - 3s 334us/sample - loss: 0.2921 - precision: 0.6293 - recall: 0.8206 - acc: 0.8354\n",
      "Epoch 15/20\n",
      "8658/8658 [==============================] - 3s 347us/sample - loss: 0.2883 - precision: 0.6362 - recall: 0.8239 - acc: 0.8373\n",
      "Epoch 16/20\n",
      "8658/8658 [==============================] - 3s 363us/sample - loss: 0.2910 - precision: 0.6337 - recall: 0.8199 - acc: 0.8367\n",
      "Epoch 17/20\n",
      "8658/8658 [==============================] - 3s 382us/sample - loss: 0.2907 - precision: 0.6335 - recall: 0.8230 - acc: 0.8373\n",
      "Epoch 18/20\n",
      "8658/8658 [==============================] - 3s 339us/sample - loss: 0.2889 - precision: 0.6349 - recall: 0.8216 - acc: 0.8377\n",
      "Epoch 19/20\n",
      "8658/8658 [==============================] - 3s 336us/sample - loss: 0.2894 - precision: 0.6377 - recall: 0.8172 - acc: 0.8377\n",
      "Epoch 20/20\n",
      "8658/8658 [==============================] - 3s 374us/sample - loss: 0.2872 - precision: 0.6381 - recall: 0.8221 - acc: 0.8389\n"
     ]
    }
   ],
   "source": [
    "rnn_pipe = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "8658/8658 [==============================] - 0s 42us/sample - loss: 0.2749 - precision: 0.6368 - recall: 0.8220 - acc: 0.8392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.274935781955719, 0.6367891, 0.822026, 0.83922386]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1665/1665 [==============================] - 0s 9us/sample - loss: 0.2167 - precision: 0.7849 - recall: 0.7817 - acc: 0.8691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21673840284347534, 0.78486055, 0.78174603, 0.86906904]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "pipe = Pipeline([\n",
    "        (\"columns\", ColumnSelectTransformer(['longitude','latitude','pop','pov','nl','temp','elev','Battles','Explosions',\n",
    "             'Protests','Riots','Strategic developments','Violence against civilians',\n",
    "             'fatalities_battles','fatalities_explosions','fatalities_protests','fatalities_riots',\n",
    "             'fatalities_strategic','fatalities_civilian','month','year'])),\n",
    "        (\"one_hot\", one_hot_transformer),\n",
    "        (\"scale\",scaler),\n",
    "        (\"rnn\", RnnEstimator(past, f_loss, [precision, recall, 'accuracy'], opt, 40))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "11655/11655 [==============================] - 5s 460us/sample - loss: 0.3376 - precision: 0.6037 - recall: 0.7824 - acc: 0.8118\n",
      "Epoch 2/40\n",
      "11655/11655 [==============================] - 4s 385us/sample - loss: 0.3052 - precision: 0.6146 - recall: 0.8116 - acc: 0.8225\n",
      "Epoch 3/40\n",
      "11655/11655 [==============================] - 4s 380us/sample - loss: 0.3025 - precision: 0.6251 - recall: 0.7987 - acc: 0.8295\n",
      "Epoch 4/40\n",
      "11655/11655 [==============================] - 4s 381us/sample - loss: 0.2985 - precision: 0.6421 - recall: 0.7905 - acc: 0.8360\n",
      "Epoch 5/40\n",
      "11655/11655 [==============================] - 4s 377us/sample - loss: 0.2987 - precision: 0.6278 - recall: 0.8045 - acc: 0.8305\n",
      "Epoch 6/40\n",
      "11655/11655 [==============================] - 5s 401us/sample - loss: 0.2962 - precision: 0.6337 - recall: 0.8020 - acc: 0.8341\n",
      "Epoch 7/40\n",
      "11655/11655 [==============================] - 4s 377us/sample - loss: 0.2962 - precision: 0.6369 - recall: 0.8008 - acc: 0.8360\n",
      "Epoch 8/40\n",
      "11655/11655 [==============================] - 4s 380us/sample - loss: 0.2960 - precision: 0.6410 - recall: 0.7938 - acc: 0.8372\n",
      "Epoch 9/40\n",
      "11655/11655 [==============================] - 5s 404us/sample - loss: 0.2911 - precision: 0.6409 - recall: 0.8051 - acc: 0.8369\n",
      "Epoch 10/40\n",
      "11655/11655 [==============================] - 4s 383us/sample - loss: 0.2940 - precision: 0.6365 - recall: 0.8055 - acc: 0.8359\n",
      "Epoch 11/40\n",
      "11655/11655 [==============================] - 5s 427us/sample - loss: 0.2887 - precision: 0.6474 - recall: 0.8062 - acc: 0.8394\n",
      "Epoch 12/40\n",
      "11655/11655 [==============================] - 5s 390us/sample - loss: 0.2893 - precision: 0.6457 - recall: 0.8043 - acc: 0.8388\n",
      "Epoch 13/40\n",
      "11655/11655 [==============================] - 4s 347us/sample - loss: 0.2846 - precision: 0.6509 - recall: 0.8099 - acc: 0.8404\n",
      "Epoch 14/40\n",
      "11655/11655 [==============================] - 5s 403us/sample - loss: 0.2909 - precision: 0.6450 - recall: 0.8041 - acc: 0.8391\n",
      "Epoch 15/40\n",
      "11655/11655 [==============================] - 4s 381us/sample - loss: 0.2845 - precision: 0.6553 - recall: 0.8104 - acc: 0.8408\n",
      "Epoch 16/40\n",
      "11655/11655 [==============================] - 5s 386us/sample - loss: 0.2883 - precision: 0.6448 - recall: 0.8115 - acc: 0.8397\n",
      "Epoch 17/40\n",
      "11655/11655 [==============================] - 5s 393us/sample - loss: 0.2853 - precision: 0.6491 - recall: 0.8084 - acc: 0.8403\n",
      "Epoch 18/40\n",
      "11655/11655 [==============================] - 5s 393us/sample - loss: 0.2865 - precision: 0.6487 - recall: 0.8094 - acc: 0.8407\n",
      "Epoch 19/40\n",
      "11655/11655 [==============================] - 4s 374us/sample - loss: 0.2852 - precision: 0.6464 - recall: 0.8080 - acc: 0.8406\n",
      "Epoch 20/40\n",
      "11655/11655 [==============================] - 4s 343us/sample - loss: 0.2823 - precision: 0.6508 - recall: 0.8180 - acc: 0.8414\n",
      "Epoch 21/40\n",
      "11655/11655 [==============================] - 4s 358us/sample - loss: 0.2812 - precision: 0.6502 - recall: 0.8159 - acc: 0.8419\n",
      "Epoch 22/40\n",
      "11655/11655 [==============================] - 4s 348us/sample - loss: 0.2820 - precision: 0.6535 - recall: 0.8111 - acc: 0.8425\n",
      "Epoch 23/40\n",
      "11655/11655 [==============================] - 4s 371us/sample - loss: 0.2825 - precision: 0.6503 - recall: 0.8147 - acc: 0.8409\n",
      "Epoch 24/40\n",
      "11655/11655 [==============================] - 5s 394us/sample - loss: 0.2825 - precision: 0.6459 - recall: 0.8112 - acc: 0.8418\n",
      "Epoch 25/40\n",
      "11655/11655 [==============================] - 4s 371us/sample - loss: 0.2871 - precision: 0.6477 - recall: 0.8093 - acc: 0.8421\n",
      "Epoch 26/40\n",
      "11655/11655 [==============================] - 5s 392us/sample - loss: 0.2845 - precision: 0.6548 - recall: 0.8103 - acc: 0.8430\n",
      "Epoch 27/40\n",
      "11655/11655 [==============================] - 4s 377us/sample - loss: 0.2840 - precision: 0.6507 - recall: 0.8123 - acc: 0.8430\n",
      "Epoch 28/40\n",
      "11655/11655 [==============================] - 4s 362us/sample - loss: 0.2824 - precision: 0.6498 - recall: 0.8107 - acc: 0.8426\n",
      "Epoch 29/40\n",
      "11655/11655 [==============================] - 4s 360us/sample - loss: 0.2828 - precision: 0.6501 - recall: 0.8108 - acc: 0.8433\n",
      "Epoch 30/40\n",
      "11655/11655 [==============================] - 4s 384us/sample - loss: 0.2825 - precision: 0.6557 - recall: 0.8118 - acc: 0.8431\n",
      "Epoch 31/40\n",
      "11655/11655 [==============================] - 5s 399us/sample - loss: 0.2824 - precision: 0.6544 - recall: 0.8107 - acc: 0.8431\n",
      "Epoch 32/40\n",
      "11655/11655 [==============================] - 5s 398us/sample - loss: 0.2823 - precision: 0.6532 - recall: 0.8094 - acc: 0.8434\n",
      "Epoch 33/40\n",
      "11655/11655 [==============================] - 4s 382us/sample - loss: 0.2823 - precision: 0.6539 - recall: 0.8141 - acc: 0.8434\n",
      "Epoch 34/40\n",
      "11655/11655 [==============================] - 4s 383us/sample - loss: 0.2803 - precision: 0.6547 - recall: 0.8164 - acc: 0.8435\n",
      "Epoch 35/40\n",
      "11655/11655 [==============================] - 4s 366us/sample - loss: 0.2849 - precision: 0.6517 - recall: 0.8116 - acc: 0.8437\n",
      "Epoch 36/40\n",
      "11655/11655 [==============================] - 4s 362us/sample - loss: 0.2796 - precision: 0.6538 - recall: 0.8174 - acc: 0.8437\n",
      "Epoch 37/40\n",
      "11655/11655 [==============================] - 4s 374us/sample - loss: 0.2786 - precision: 0.6571 - recall: 0.8157 - acc: 0.8437\n",
      "Epoch 38/40\n",
      "11655/11655 [==============================] - 4s 364us/sample - loss: 0.2840 - precision: 0.6474 - recall: 0.8085 - acc: 0.8437\n",
      "Epoch 39/40\n",
      "11655/11655 [==============================] - 5s 400us/sample - loss: 0.2816 - precision: 0.6546 - recall: 0.8119 - acc: 0.8439\n",
      "Epoch 40/40\n",
      "11655/11655 [==============================] - 4s 371us/sample - loss: 0.2823 - precision: 0.6531 - recall: 0.8137 - acc: 0.8438\n"
     ]
    }
   ],
   "source": [
    "rnn_pipe = pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "11655/11655 [==============================] - 0s 34us/sample - loss: 0.2778 - precision: 0.6413 - recall: 0.8087 - acc: 0.8378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27782291173934937, 0.64129555, 0.80871344, 0.83775204]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naive = X.copy()\n",
    "\n",
    "X_naive = X_naive.dropna(subset=['y_next']).reset_index(drop = True)\n",
    "\n",
    "true_positives = sum((X_naive['y_next'] * X_naive['y']).values)\n",
    "predicted_positives = sum(X_naive['y'].values)\n",
    "possible_positives = sum((X_naive['y_next']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6294670846394984"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6275"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for September 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = X.copy()\n",
    "X_pred = X_pred[(X_pred['month_year'] >= '2018-09') & (X_pred['month_year'] < '2019-09')].reset_index(drop=True)\n",
    "\n",
    "predictions = rnn_pipe.predict(X_pred)\n",
    "lat_lon = X_pred.iloc[::12, :].reset_index(drop=True)[['longitude','latitude']]\n",
    "lat_lon['pred'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Predictions for September 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = conflict[conflict['month_year'] == pd.to_datetime('2019-08-01')]\n",
    "naive = pd.merge(pred[['longitude','latitude']],naive, on = ['longitude','latitude'], how = 'left')\n",
    "naive.loc[naive.month_year.isnull(),['month_year']] = pd.to_datetime('2019-08-01')\n",
    "naive['month_year'] = naive['month_year'].dt.strftime('%Y-%m')\n",
    "naive = naive.fillna(0)\n",
    "naive = naive.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)\n",
    "naive['naive_pred'] = naive.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                                   + row['Violence against civilians']) != 0), axis=1)\n",
    "\n",
    "naive = naive[['longitude','latitude','naive_pred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual values for September 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = conflict[conflict['month_year'] == pd.to_datetime('2019-09-01')]\n",
    "actual = pd.merge(pred[['longitude','latitude']],actual, on = ['longitude','latitude'], how = 'left')\n",
    "actual.loc[actual.month_year.isnull(),['month_year']] = pd.to_datetime('2019-09-01')\n",
    "actual['month_year'] = actual['month_year'].dt.strftime('%Y-%m')\n",
    "actual = actual.fillna(0)\n",
    "actual = actual.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)\n",
    "actual['actual'] = actual.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                                 + row['Violence against civilians']) != 0), axis=1)\n",
    "\n",
    "actual = actual[['longitude','latitude','actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.merge(lat_lon, naive, on = ['longitude','latitude'])\n",
    "compare = pd.merge(compare, actual, on = ['longitude','latitude'])\n",
    "\n",
    "true_positives = sum((compare['actual'] * (compare['pred'] > 0.5).astype('int')).values)\n",
    "predicted_positives = sum(((compare['pred'] > 0.5).astype('int')).values)\n",
    "possible_positives = sum((compare['actual']).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision and Recall for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision and Recall for Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = sum((compare['actual'] * compare['naive_pred']).values)\n",
    "predicted_positives = sum((compare['naive_pred']).values)\n",
    "possible_positives = sum((compare['actual']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone Development",
   "language": "python",
   "name": "capstone-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
