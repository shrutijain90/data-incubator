{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from sklearn import base\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = pd.read_csv('data/conflict.csv')\n",
    "pred = pd.read_csv('data/pak_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['event_date'] =  pd.to_datetime(conflict['event_date'], format='%d %B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['Battles'] = conflict['event_type'] == 'Battles'\n",
    "conflict['Explosions'] = conflict['event_type'] == 'Explosions/Remote violence'\n",
    "conflict['Protests'] = conflict['event_type'] == 'Protests'\n",
    "conflict['Riots'] = conflict['event_type'] == 'Riots'\n",
    "conflict['Strategic developments'] = conflict['event_type'] == 'Strategic developments'\n",
    "conflict['Violence against civilians'] = conflict['event_type'] == 'Violence against civilians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['month_year'] = conflict.event_date.values.astype('datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict  = conflict[['month_year','latitude','longitude','Battles','Explosions','Protests','Riots',\n",
    "                      'Strategic developments','Violence against civilians','fatalities','admin1','admin2','admin3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict['fatalities_battles'] = conflict['fatalities'] * conflict['Battles']\n",
    "conflict['fatalities_explosions'] = conflict['fatalities'] * conflict['Explosions']\n",
    "conflict['fatalities_protests'] = conflict['fatalities'] * conflict['Protests']\n",
    "conflict['fatalities_riots'] = conflict['fatalities'] * conflict['Riots']\n",
    "conflict['fatalities_strategic'] = conflict['fatalities'] * conflict['Strategic developments']\n",
    "conflict['fatalities_civilian'] = conflict['fatalities'] * conflict['Violence against civilians']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = conflict.groupby(['month_year','latitude','longitude']).agg({'Battles':'sum',\n",
    "                                                             'Explosions':'sum',\n",
    "                                                             'Protests':'sum',\n",
    "                                                             'Riots':'sum',\n",
    "                                                             'Strategic developments':'sum',\n",
    "                                                             'Violence against civilians':'sum',\n",
    "                                                             'fatalities_battles':'sum',\n",
    "                                                             'fatalities_explosions':'sum',\n",
    "                                                             'fatalities_protests':'sum',\n",
    "                                                             'fatalities_riots':'sum',\n",
    "                                                             'fatalities_strategic':'sum',\n",
    "                                                             'fatalities_civilian':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.loc[:, ~pred.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.rename(columns={\"x\": \"longitude\", \"y\": \"latitude\", \"pak_ppp_2015\": \"pop\", \"pak07povmpi\": \"pov\", \n",
    "                     \"F182013.v4c_web.stable_lights.avg_vis\": \"nl\", \"index_1\": \"temp\", \"layer\": \"elev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.dropna(subset=['pop', 'pov','nl','temp','elev'], how = 'all').reset_index(drop = True)\n",
    "pred = pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(pred[['longitude','latitude']],conflict, on = ['longitude','latitude'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X.month_year.isnull(),['month_year']] = pd.to_datetime('2010-01-01')\n",
    "X = X[X['month_year'] != pd.to_datetime('2019-10-01')]\n",
    "X['month_year'] = X['month_year'].dt.strftime('%Y-%m')\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2010-01-01','2019-09-01', \n",
    "              freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "coor = pred[['longitude','latitude']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [coor,dates]\n",
    "data = list(itertools.product(*a))\n",
    "df = pd.DataFrame(data, columns=['coor','month_year'])\n",
    "df[['longitude','latitude']] = pd.DataFrame(df.coor.values.tolist(), index= df.index)\n",
    "df = df[['longitude','latitude','month_year']].sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(df,X, on = ['longitude','latitude','month_year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(pred,X, on = ['longitude','latitude'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = X.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                  + row['Violence against civilians']) != 0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['month'] = X.apply(lambda row: int(row['month_year'].split('-')[1]), axis=1)\n",
    "X['year'] = X.apply(lambda row: int(row['month_year'].split('-')[0]), axis=1)\n",
    "X['year'] = X['year'] - 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y_next'] = X.shift(-1).y\n",
    "X.loc[X.index.to_series().groupby([X['longitude'],X['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "y = X['y_next'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = X[self.col_names].values\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_transformer = ColumnTransformer([(\"onehot\", OneHotEncoder(categories='auto', sparse=False),slice(19,20))], \n",
    "                                        remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ColumnTransformer([(\"standard\", StandardScaler(),slice(12,19))], \n",
    "                                        remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    beta = 1.15\n",
    "\n",
    "    f1 = (1 + (beta**2))*p*r / ((beta**2) * p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnEstimator(base.BaseEstimator, base.ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, past, loss, metrics, opt, epochs):\n",
    "        self.past = past\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.opt = opt\n",
    "        self.model = Sequential()\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_list = X.tolist()\n",
    "        y_list = y.tolist()\n",
    "        n = len(X_list)\n",
    "        y_list = [y_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        X_list = [X_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        \n",
    "        to_remove = [i for i in range(len(y_list)) if True in [math.isnan(item) for item in y_list[i]]]\n",
    "\n",
    "        for index in sorted(to_remove, reverse=True):\n",
    "            del y_list[index]\n",
    "            del X_list[index]\n",
    "        y_list = [int(item[-1]) for item in y_list]\n",
    "        \n",
    "        y = np.array(y_list)\n",
    "        X = np.array(X_list)\n",
    "        \n",
    "        n_steps = X.shape[1]\n",
    "        n_features = X.shape[2]\n",
    "        \n",
    "        self.model.add(LSTM(10, input_shape=(n_steps, n_features)))\n",
    "        self.model.add(Dense(5, activation='tanh'))\n",
    "        self.model.add(Dense(10, activation='tanh'))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        self.model.compile(optimizer=self.opt, loss=self.loss, metrics=self.metrics)\n",
    "        \n",
    "        self.model.fit(X, y, epochs=self.epochs)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        X_list = X.tolist()\n",
    "        y_list = y.tolist()\n",
    "        n = len(X_list)\n",
    "        y_list = [y_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        X_list = [X_list[i:i+self.past] for i in range(n - self.past + 1)]\n",
    "        \n",
    "        to_remove = [i for i in range(len(y_list)) if True in [math.isnan(item) for item in y_list[i]]]\n",
    "\n",
    "        for index in sorted(to_remove, reverse=True):\n",
    "            del y_list[index]\n",
    "            del X_list[index]\n",
    "        y_list = [int(item[-1]) for item in y_list]\n",
    "        \n",
    "        y = np.array(y_list)\n",
    "        X = np.array(X_list)\n",
    "        \n",
    "        return self.model.evaluate(X, y, batch_size = X.shape[0])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_list = X.tolist()\n",
    "        n = len(X_list)\n",
    "        X_list = [X_list[i:i+self.past] for i in range(0, n - self.past +1, self.past)]\n",
    "        X = np.array(X_list)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['month_year'] < '2016-08'].copy()\n",
    "X_test = X[X['month_year'] >= '2016-08'].copy()\n",
    "\n",
    "X_train['y_next'] = X_train.shift(-1).y\n",
    "X_train.loc[X_train.index.to_series().groupby([X_train['longitude'], \n",
    "                                               X_train['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "X_test['y_next'] = X_test.shift(-1).y\n",
    "X_test.loc[X_test.index.to_series().groupby([X_test['longitude'], \n",
    "                                             X_test['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "y_train = X_train['y_next'].values\n",
    "\n",
    "y_test = X_test['y_next'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "pipe = Pipeline([\n",
    "        (\"columns\", ColumnSelectTransformer(['longitude','latitude','pop','pov','nl','temp','elev','Battles','Explosions',\n",
    "             'Protests','Riots','Strategic developments','Violence against civilians',\n",
    "             'fatalities_battles','fatalities_explosions','fatalities_protests','fatalities_riots',\n",
    "             'fatalities_strategic','fatalities_civilian','month','year','y'])),\n",
    "        (\"one_hot\", one_hot_transformer),\n",
    "        (\"scale\",scaler),\n",
    "        (\"rnn\", RnnEstimator(past, f_loss, [precision, recall, 'accuracy'], opt, 20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12864/12864 [==============================] - 5s 425us/sample - loss: 0.3632 - precision: 0.5946 - recall: 0.7706 - acc: 0.8567\n",
      "Epoch 2/20\n",
      "12864/12864 [==============================] - 5s 418us/sample - loss: 0.3224 - precision: 0.5737 - recall: 0.8375 - acc: 0.8670\n",
      "Epoch 3/20\n",
      "12864/12864 [==============================] - 5s 361us/sample - loss: 0.3132 - precision: 0.6028 - recall: 0.8137 - acc: 0.8765\n",
      "Epoch 4/20\n",
      "12864/12864 [==============================] - 5s 361us/sample - loss: 0.3080 - precision: 0.6301 - recall: 0.7941 - acc: 0.8844\n",
      "Epoch 5/20\n",
      "12864/12864 [==============================] - 5s 414us/sample - loss: 0.3111 - precision: 0.6314 - recall: 0.7787 - acc: 0.8874\n",
      "Epoch 6/20\n",
      "12864/12864 [==============================] - 5s 394us/sample - loss: 0.3073 - precision: 0.6216 - recall: 0.8033 - acc: 0.8852\n",
      "Epoch 7/20\n",
      "12864/12864 [==============================] - 5s 391us/sample - loss: 0.3080 - precision: 0.6260 - recall: 0.7954 - acc: 0.8859\n",
      "Epoch 8/20\n",
      "12864/12864 [==============================] - 5s 387us/sample - loss: 0.3045 - precision: 0.6315 - recall: 0.7937 - acc: 0.8864\n",
      "Epoch 9/20\n",
      "12864/12864 [==============================] - 5s 397us/sample - loss: 0.3071 - precision: 0.6290 - recall: 0.7996 - acc: 0.8872\n",
      "Epoch 10/20\n",
      "12864/12864 [==============================] - 5s 389us/sample - loss: 0.3049 - precision: 0.6346 - recall: 0.7865 - acc: 0.8889\n",
      "Epoch 11/20\n",
      "12864/12864 [==============================] - 5s 394us/sample - loss: 0.3003 - precision: 0.6377 - recall: 0.7936 - acc: 0.8890\n",
      "Epoch 12/20\n",
      "12864/12864 [==============================] - 5s 374us/sample - loss: 0.2991 - precision: 0.6417 - recall: 0.7999 - acc: 0.8896\n",
      "Epoch 13/20\n",
      "12864/12864 [==============================] - 5s 351us/sample - loss: 0.2941 - precision: 0.6424 - recall: 0.8012 - acc: 0.8898\n",
      "Epoch 14/20\n",
      "12864/12864 [==============================] - 5s 362us/sample - loss: 0.2962 - precision: 0.6407 - recall: 0.7990 - acc: 0.8900\n",
      "Epoch 15/20\n",
      "12864/12864 [==============================] - 5s 375us/sample - loss: 0.2969 - precision: 0.6448 - recall: 0.7972 - acc: 0.8905\n",
      "Epoch 16/20\n",
      "12864/12864 [==============================] - 5s 389us/sample - loss: 0.2940 - precision: 0.6496 - recall: 0.8024 - acc: 0.8912\n",
      "Epoch 17/20\n",
      "12864/12864 [==============================] - 5s 403us/sample - loss: 0.2969 - precision: 0.6472 - recall: 0.7957 - acc: 0.8907\n",
      "Epoch 18/20\n",
      "12864/12864 [==============================] - 5s 380us/sample - loss: 0.3001 - precision: 0.6388 - recall: 0.7970 - acc: 0.8913\n",
      "Epoch 19/20\n",
      "12864/12864 [==============================] - 5s 381us/sample - loss: 0.2933 - precision: 0.6476 - recall: 0.8003 - acc: 0.8916\n",
      "Epoch 20/20\n",
      "12864/12864 [==============================] - 5s 377us/sample - loss: 0.2953 - precision: 0.6443 - recall: 0.8037 - acc: 0.8917\n"
     ]
    }
   ],
   "source": [
    "rnn_pipe = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "12864/12864 [==============================] - 0s 25us/sample - loss: 0.2745 - precision: 0.6486 - recall: 0.7993 - acc: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2745162844657898, 0.6486085, 0.7992684, 0.89225745]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "4992/4992 [==============================] - 0s 6us/sample - loss: 0.2775 - precision: 0.6689 - recall: 0.7693 - acc: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27750539779663086, 0.668906, 0.76931566, 0.8890224]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X[X['month_year'] < '2019-09'].copy()\n",
    "\n",
    "X_full['y_next'] = X_train.shift(-1).y\n",
    "X_full.loc[X_train.index.to_series().groupby([X_train['longitude'], \n",
    "                                               X_train['latitude']]).last().reset_index(name='x')['x'],'y_next'] = np.nan\n",
    "\n",
    "y_full = X_full['y_next'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "pipe = Pipeline([\n",
    "        (\"columns\", ColumnSelectTransformer(['longitude','latitude','pop','pov','nl','temp','elev','Battles','Explosions',\n",
    "             'Protests','Riots','Strategic developments','Violence against civilians',\n",
    "             'fatalities_battles','fatalities_explosions','fatalities_protests','fatalities_riots',\n",
    "             'fatalities_strategic','fatalities_civilian','month','year'])),\n",
    "        (\"one_hot\", one_hot_transformer),\n",
    "        (\"scale\",scaler),\n",
    "        (\"rnn\", RnnEstimator(past, f_loss, [precision, recall, 'accuracy'], opt, 20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20160/20160 [==============================] - 9s 457us/sample - loss: 0.3321 - precision: 0.6082 - recall: 0.7820 - acc: 0.8702\n",
      "Epoch 2/20\n",
      "20160/20160 [==============================] - 8s 402us/sample - loss: 0.3107 - precision: 0.6253 - recall: 0.7935 - acc: 0.8821\n",
      "Epoch 3/20\n",
      "20160/20160 [==============================] - 8s 410us/sample - loss: 0.3133 - precision: 0.6193 - recall: 0.7903 - acc: 0.8829\n",
      "Epoch 4/20\n",
      "20160/20160 [==============================] - 8s 406us/sample - loss: 0.3053 - precision: 0.6214 - recall: 0.8082 - acc: 0.8817\n",
      "Epoch 5/20\n",
      "20160/20160 [==============================] - 8s 406us/sample - loss: 0.3043 - precision: 0.6242 - recall: 0.8036 - acc: 0.8836\n",
      "Epoch 6/20\n",
      "20160/20160 [==============================] - 8s 382us/sample - loss: 0.3044 - precision: 0.6257 - recall: 0.8015 - acc: 0.8845\n",
      "Epoch 7/20\n",
      "20160/20160 [==============================] - 8s 400us/sample - loss: 0.3014 - precision: 0.6268 - recall: 0.8045 - acc: 0.8846\n",
      "Epoch 8/20\n",
      "20160/20160 [==============================] - 9s 449us/sample - loss: 0.2959 - precision: 0.6328 - recall: 0.8162 - acc: 0.8840\n",
      "Epoch 9/20\n",
      "20160/20160 [==============================] - 8s 393us/sample - loss: 0.2963 - precision: 0.6352 - recall: 0.8084 - acc: 0.8859\n",
      "Epoch 10/20\n",
      "20160/20160 [==============================] - 8s 401us/sample - loss: 0.2972 - precision: 0.6314 - recall: 0.8087 - acc: 0.8862\n",
      "Epoch 11/20\n",
      "20160/20160 [==============================] - 8s 404us/sample - loss: 0.2975 - precision: 0.6350 - recall: 0.8080 - acc: 0.8866\n",
      "Epoch 12/20\n",
      "20160/20160 [==============================] - 8s 376us/sample - loss: 0.2930 - precision: 0.6354 - recall: 0.8168 - acc: 0.8866\n",
      "Epoch 13/20\n",
      "20160/20160 [==============================] - 8s 380us/sample - loss: 0.2963 - precision: 0.6367 - recall: 0.8095 - acc: 0.8871\n",
      "Epoch 14/20\n",
      "20160/20160 [==============================] - 9s 435us/sample - loss: 0.2939 - precision: 0.6347 - recall: 0.8151 - acc: 0.8872\n",
      "Epoch 15/20\n",
      "20160/20160 [==============================] - 8s 378us/sample - loss: 0.2970 - precision: 0.6351 - recall: 0.8098 - acc: 0.8875\n",
      "Epoch 16/20\n",
      "20160/20160 [==============================] - 7s 368us/sample - loss: 0.2957 - precision: 0.6346 - recall: 0.8156 - acc: 0.8874\n",
      "Epoch 17/20\n",
      "20160/20160 [==============================] - 8s 403us/sample - loss: 0.2916 - precision: 0.6370 - recall: 0.8140 - acc: 0.8877\n",
      "Epoch 18/20\n",
      "20160/20160 [==============================] - 8s 372us/sample - loss: 0.2910 - precision: 0.6410 - recall: 0.8124 - acc: 0.8874\n",
      "Epoch 19/20\n",
      "20160/20160 [==============================] - 8s 373us/sample - loss: 0.2902 - precision: 0.6429 - recall: 0.8136 - acc: 0.8879\n",
      "Epoch 20/20\n",
      "20160/20160 [==============================] - 8s 397us/sample - loss: 0.2949 - precision: 0.6343 - recall: 0.8125 - acc: 0.8877\n"
     ]
    }
   ],
   "source": [
    "rnn_pipe = pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20160/20160 [==============================] - 1s 31us/sample - loss: 0.2738 - precision: 0.6366 - recall: 0.8150 - acc: 0.8879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.273811936378479, 0.6366292, 0.8150173, 0.88789684]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pipe.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naive = X.copy()\n",
    "\n",
    "X_naive = X_naive.dropna(subset=['y_next']).reset_index(drop = True)\n",
    "\n",
    "true_positives = sum((X_naive['y_next'] * X_naive['y']).values)\n",
    "predicted_positives = sum(X_naive['y'].values)\n",
    "possible_positives = sum((X_naive['y_next']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6312598840274117"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6297659742308703"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for September 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = X.copy()\n",
    "X_pred = X_pred[(X_pred['month_year'] >= '2018-09') & (X_pred['month_year'] < '2019-09')].reset_index(drop=True)\n",
    "\n",
    "predictions = rnn_pipe.predict(X_pred)\n",
    "lat_lon = X_pred.iloc[::12, :].reset_index(drop=True)[['longitude','latitude']]\n",
    "lat_lon['pred'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Predictions for September 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = conflict[conflict['month_year'] == pd.to_datetime('2019-08-01')]\n",
    "naive = pd.merge(pred[['longitude','latitude']],naive, on = ['longitude','latitude'], how = 'left')\n",
    "naive.loc[naive.month_year.isnull(),['month_year']] = pd.to_datetime('2019-08-01')\n",
    "naive['month_year'] = naive['month_year'].dt.strftime('%Y-%m')\n",
    "naive = naive.fillna(0)\n",
    "naive = naive.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)\n",
    "naive['naive_pred'] = naive.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                                   + row['Violence against civilians']) != 0), axis=1)\n",
    "\n",
    "naive = naive[['longitude','latitude','naive_pred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual values for September 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = conflict[conflict['month_year'] == pd.to_datetime('2019-09-01')]\n",
    "actual = pd.merge(pred[['longitude','latitude']],actual, on = ['longitude','latitude'], how = 'left')\n",
    "actual.loc[actual.month_year.isnull(),['month_year']] = pd.to_datetime('2019-09-01')\n",
    "actual['month_year'] = actual['month_year'].dt.strftime('%Y-%m')\n",
    "actual = actual.fillna(0)\n",
    "actual = actual.sort_values(by = ['longitude','latitude','month_year']).reset_index(drop=True)\n",
    "actual['actual'] = actual.apply(lambda row: int((row['Battles'] + row['Explosions'] + row['Riots'] \n",
    "                                                 + row['Violence against civilians']) != 0), axis=1)\n",
    "\n",
    "actual = actual[['longitude','latitude','actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.merge(lat_lon, naive, on = ['longitude','latitude'])\n",
    "compare = pd.merge(compare, actual, on = ['longitude','latitude'])\n",
    "\n",
    "true_positives = sum((compare['actual'] * (compare['pred'] > 0.5).astype('int')).values)\n",
    "predicted_positives = sum(((compare['pred'] > 0.5).astype('int')).values)\n",
    "possible_positives = sum((compare['actual']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.to_csv(\"data/predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision and Recall for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409090909090909"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision and Recall for Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = sum((compare['actual'] * compare['naive_pred']).values)\n",
    "predicted_positives = sum((compare['naive_pred']).values)\n",
    "possible_positives = sum((compare['actual']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / predicted_positives #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives / possible_positives #recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone Development",
   "language": "python",
   "name": "capstone-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
